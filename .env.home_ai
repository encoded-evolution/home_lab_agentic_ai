##################################################### 
# ENV FILE
# Environment settings to support:
# 	- Ollama
# 	- N8N
# 	- PostgresSQL/with AGE, Vector
# 	- LightRAG
# 	- CRAWL4AI
# 	- Selenium
# 	- pgAdmin
# 	- Open Webui
# 	- QDrant (if postgres vector is not supportable)
#####################################################

#####################################################
# Postgres SETTINGS
#####################################################
POSTGRES_HOST=db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=postgres
POSTGRES_PORT=5432
POSTGRES_MAX_CONNECTIONS=12
PGADMIN_DEFAULT_EMAIL=Admin123@Admin123.com
PGADMIN_DEFAULT_PASSWORD=Admin123!

#####################################################
# N8N SETTINGS
#####################################################
N8N_ENCRYPTION_KEY=
N8N_USER_MANAGEMENT_JWT_SECRET=
N8N_DEFAULT_BINARY_DATA_MODE=filesystem
N8N_NODE_FUNCTION_ALLOW_EXTERNAL=*
N8N_COMMUNITY_PACKAGES_ALLOW_TOOL_USAGE=true
N8N_SOFTWARE_VERSION_TAG

# For Mac users running OLLAMA locally
# See https://github.com/n8n-io/self-hosted-ai-starter-kit?tab=readme-ov-file#for-mac--apple-silicon-users
# OLLAMA_HOST=host.docker.internal:11434

#####################################################
# CRAWL4AI SETTINGS
#####################################################
# CRAWL4AI_API_TOKEN=testauth # Bearer Auth = "Bearer testauth"
# ENABLE_GPU=true

#####################################################
# LIGHTRAG SETTINGS
#####################################################
# LightRAG
HOST=0.0.0.0
PORT=9621
WEBUI_TITLE='LIGHTRAG'
WEBUI_DESCRIPTION="Simple and Fast Graph Based RAG System"
WORKERS=12
# OLLAMA_EMULATING_MODEL_TAG=latest
# LIGHTRAG_KV_STORAGE=PGKVStorage
# LIGHTRAG_VECTOR_STORAGE=PGVectorStorage
# LIGHTRAG_GRAPH_STORAGE=PGGraphStorage
# LIGHTRAG_DOC_STATUS_STORAGE=PGDocStatusStorage


# SUMMARY_LANGUAGE=English
# ENABLE_LLM_CACHE_FOR_EXTRACT=true

###############################
### Concurrency Configuration
###############################
### Max concurrency requests of LLM (for both query and document processing)
# MAX_ASYNC=12
### Number of parallel processing documents(between 2~10, MAX_ASYNC/3 is recommended)
# MAX_PARALLEL_INSERT=12
### Max concurrency requests for Embedding
# EMBEDDING_FUNC_MAX_ASYNC=12
### Num of chunks send to Embedding in single request
# EMBEDDING_BATCH_NUM=100

#####################################################
# OLLAMA SETTINGS - joint between the ollama service
# 		and also LightRAG and N8N
#####################################################

### LLM Binding type: openai, ollama, lollms, azure_openai
# LLM_BINDING=ollama
# LLM_MODEL=llama3.2:latest
# LLM_BINDING_HOST=host.docker.internal:11434
# LLM_BINDING_API_KEY=

### Most Common Parameters for Ollama Server
### see also env.ollama-binding-options.example for fine tuning ollama
### OLLAMA_LLM_NUM_CTX must be larger than MAX_TOTAL_TOKENS + 2000
# OLLAMA_LLM_NUM_CTX=32768
### Time out in seconds, None for infinite timeout
# TIMEOUT=240

### see also env.ollama-binding-options.example for fine tuning ollama
# EMBEDDING_BINDING=ollama
# EMBEDDING_MODEL=nomic-embed-text:latest
# EMBEDDING_DIM=768
# EMBEDDING_BINDING_API_KEY=
# If the embedding service is deployed within the same Docker stack, use host.docker.internal instead of localhost
# EMBEDDING_BINDING_HOST=http://host.docker.internal:11434



#=================================================================
#=================================================================
# Above is MVP
#=================================================================

#####################################################
# QDRANT SETTINGS
#####################################################
# QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=your-api-key
# QDRANT_WORKSPACE=default


### Neo4j Configuration
# NEO4J_URI=neo4j+s://xxxxxxxx.databases.neo4j.io
# NEO4J_MAX_CONNECTION_POOL_SIZE=100
# NEO4J_CONNECTION_TIMEOUT=30
# NEO4J_CONNECTION_ACQUISITION_TIMEOUT=30
# MAX_TRANSACTION_RETRY_TIME=30
# NEO4J_AUTH=none
# NEO4J_USERNAME=neo4j
# NEO4J_PASSWORD='your_password'
# NEO4J_WORKSPACE=forced_workspace_name

### MongoDB Configuration
# MONGO_URI=mongodb://root:root@localhost:27017/
# MONGO_URI=mongodb+srv://xxxx
# MONGO_DATABASE=LightRAG
# MONGODB_WORKSPACE=forced_workspace_name

### Milvus Configuration
# MILVUS_URI=http://localhost:19530
# MILVUS_DB_NAME=lightrag
# MILVUS_USER=root
# MILVUS_PASSWORD=your_password
# MILVUS_TOKEN=your_token
# MILVUS_WORKSPACE=forced_workspace_name

### Redis
# REDIS_URI=redis://localhost:6379
# REDIS_SOCKET_TIMEOUT=30
# REDIS_CONNECT_TIMEOUT=10
# REDIS_MAX_CONNECTIONS=100
# REDIS_RETRY_ATTEMPTS=3
# REDIS_WORKSPACE=forced_workspace_name

### Memgraph Configuration
# MEMGRAPH_URI=bolt://localhost:7687
# MEMGRAPH_USERNAME=
# MEMGRAPH_PASSWORD=
# MEMGRAPH_DATABASE=memgraph
# MEMGRAPH_WORKSPACE=forced_workspace_name

### Reranker configuration (Set ENABLE_RERANK to true in reranking model is configed)
# ENABLE_RERANK=True
### Minimum rerank score for document chunk exclusion (set to 0.0 to keep all chunks, 0.6 or above if LLM is not strong enough)
# MIN_RERANK_SCORE=0.0
### Rerank model configuration (required when ENABLE_RERANK=True)
# RERANK_MODEL=bge-reranker-v2-m3:latest
# RERANK_BINDING_HOST=host.docker.internal:11434
# RERANK_BINDING_API_KEY=